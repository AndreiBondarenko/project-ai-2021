{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we retrieve our dataset and preprocess it into a format that is ready to use for training our matrix factorization based recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import json\n",
    "import gzip\n",
    "import math\n",
    "tqdm.pandas() # for progress_apply etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we download the files for our dataset (Goodreads). We use the gdown package to retrieve them from the Google Drive they're originally hosted on. \n",
    "\n",
    "> Since we will be implementing a collaborative filtering algorithm, we only need the interactions part of the dataset. The code for reading in the other parts of the dataset were left as comments for potential future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the URLs for each file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS = {\n",
    "    # \"BOOKS\": \"https://drive.google.com/uc?id=1ICk5x0HXvXDp5Zt54CKPh5qz1HyUIn9m\",\n",
    "    # \"AUTHORS\": \"https://drive.google.com/uc?id=19cdwyXwfXx_HDIgxXaHzH0mrx8nMyLvC\",\n",
    "    # \"REVIEWS\": \"https://drive.google.com/u/0/uc?id=1V4MLeoEiPQdocCbUHjR_7L9ZmxTufPFe\",\n",
    "    \"INTERACTIONS\": \"https://drive.google.com/uc?id=1CCj-cQw_mJLMdvF_YYfQ7ibKA-dC_GA2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and download each file. (if they haven't been downloaded in a previous run of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: ./data/INTERACTIONS.json.gz\n"
     ]
    }
   ],
   "source": [
    "for name, url in URLS.items():\n",
    "    gdown.cached_download(url, f\"./data/{name}.json.gz\", quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function to read the dataset into a Pandas dataframe. This implementation is faster and more memory efficient than the read_json function provided by Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_fast(filename, nrows=None):\n",
    "  \"\"\"\n",
    "  Loads line delimited JSON files faster than the \n",
    "  read_json function provided by Pandas.\n",
    "  \n",
    "  Iterates over file line per line, so shouldn't\n",
    "  cause out-of-memory issues, except if resulting\n",
    "  DataFrame is too big.\n",
    "  \n",
    "  Args:\n",
    "    filename: path of the JSON file\n",
    "    nrows: total number of rows to read from the file\n",
    "  \n",
    "  Returns:\n",
    "    Pandas DataFrame containing (part of) the data. \n",
    "  \"\"\"\n",
    "  with gzip.open(filename) as f:\n",
    "        print(f\"Processing {filename.split('/')[-1]}:\")\n",
    "        if nrows is not None:\n",
    "            pbar = tqdm(itertools.islice(f, nrows), unit=\"lines\")\n",
    "        else:\n",
    "            pbar = tqdm(f, unit=\"lines\")\n",
    "        return pd.DataFrame(json.loads(l) for l in pbar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the dataset file locations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_file = './data/BOOKS.json.gz' # book metadata\n",
    "interactions_file = './data/INTERACTIONS.json.gz' # user-book interactions (ratings)\n",
    "# reviews_file = './data/REVIEWS.json.gz' # user-book interactions (reviews)\n",
    "# authors_file = './data/AUTHORS.json.gz' # author metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and load the necessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing INTERACTIONS.json.gz:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c6ccedd097444ea733e1afc055d248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0lines [00:00, ?lines/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_books = read_json_fast(books_file)\n",
    "df_interactions = read_json_fast(interactions_file)\n",
    "# df_authors =  read_json_fast(authors_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the contents of the loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>is_read</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text_incomplete</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>836610</td>\n",
       "      <td>6b4db26aafeaf0da77c7de6214331e1e</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Mon Aug 21 12:11:00 -0700 2017</td>\n",
       "      <td>Mon Aug 21 12:11:00 -0700 2017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id book_id                         review_id  \\\n",
       "0  8842281e1d1347389f2ab93d60773d4d  836610  6b4db26aafeaf0da77c7de6214331e1e   \n",
       "\n",
       "   is_read  rating review_text_incomplete                      date_added  \\\n",
       "0    False       0                         Mon Aug 21 12:11:00 -0700 2017   \n",
       "\n",
       "                     date_updated read_at started_at  \n",
       "0  Mon Aug 21 12:11:00 -0700 2017                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_interactions.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataset contains quite a few columns that are of no use to us. To make everything a little less cluttered we remove the columns that we don't use from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactions = df_interactions[['user_id', 'book_id', 'rating', 'date_updated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>836610</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Aug 21 12:11:00 -0700 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id book_id  rating  \\\n",
       "0  8842281e1d1347389f2ab93d60773d4d  836610       0   \n",
       "\n",
       "                     date_updated  \n",
       "0  Mon Aug 21 12:11:00 -0700 2017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_interactions.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pre-processing step we apply is converting all dates into a more standardized format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ff985a424a4c31b90a7e4bb7471310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7347630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format_str = '%a %b %d %H:%M:%S %z %Y' #see https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n",
    "def convert_date(date_string):\n",
    "  return pd.to_datetime(date_string, utc=True, format=format_str)\n",
    "\n",
    "_df_interactions = df_interactions.copy()\n",
    "_df_interactions['date_updated'] =  _df_interactions['date_updated'].progress_apply(convert_date)\n",
    "_df_interactions['date_updated'] = _df_interactions['date_updated'].dt.tz_localize(None)  # drops utc timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a pre-processing function that:\n",
    "\n",
    "1. Drops ratings below 3, as we consider these to be non-relevant items fo rthe user.\n",
    "2. Removes duplicate (user, item) pairs.\n",
    "3. Removes users that occur in less than minsup interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, minsup=10):\n",
    "    \"\"\"\n",
    "    Goal: - Remove reconsumption items\n",
    "          - Remove users that have less than minsup interactions \n",
    "          - Drop ratings == 0, i.e. \"not provided\"\n",
    "               \n",
    "    :input df: Dataframe containing user_id, item_id and time\n",
    "    \"\"\"\n",
    "    # drop 0 ratings\n",
    "    before = df.shape[0]\n",
    "    df = df[(df[\"rating\"] > 0)]\n",
    "    print(\"After dropping  0-ratings: {} -> {}\".format(before,df.shape[0]))\n",
    "    # drop reconsumption items\n",
    "    before = df.shape[0]\n",
    "    df = df.drop_duplicates(subset=[\"user_id\",\"book_id\"])\n",
    "    print(\"After drop_duplicates (reconsumption items): {} -> {}\".format(before,df.shape[0]))\n",
    "    # drop users with less then minsup items in history\n",
    "    g = df.groupby('user_id', as_index=False)['book_id'].size()\n",
    "    g = g.rename({'size': 'user_sup'}, axis='columns')\n",
    "    df = pd.merge(df, g, how='left', on=['user_id'])\n",
    "    before = df.shape[0]\n",
    "    df = df[df['user_sup'] >= minsup]\n",
    "    print(\"After dropping users with less than {} interactions: {} -> {}\".format(minsup, before,df.shape[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply the pre-processing function to the dataframe and log the change in number of samples, number of unique users and number of unique items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique users: 342415\n",
      "number of unique items: 89411\n",
      "After dropping  0-ratings: 7347630 -> 4514094\n",
      "After drop_duplicates (reconsumption items): 4514094 -> 4514094\n",
      "After dropping users with less than 10 interactions: 4514094 -> 4041762\n",
      "number of unique users: 68401\n",
      "number of unique items: 88276\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>user_sup</th>\n",
       "      <th>user_id_seq</th>\n",
       "      <th>book_id_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>06316bec7a49286f1f98d5acce24f923</td>\n",
       "      <td>575753</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-05 16:35:39</td>\n",
       "      <td>35</td>\n",
       "      <td>1721</td>\n",
       "      <td>73285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>06316bec7a49286f1f98d5acce24f923</td>\n",
       "      <td>47694</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-05 16:35:15</td>\n",
       "      <td>35</td>\n",
       "      <td>1721</td>\n",
       "      <td>71428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>06316bec7a49286f1f98d5acce24f923</td>\n",
       "      <td>47700</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-06-05 16:34:57</td>\n",
       "      <td>35</td>\n",
       "      <td>1721</td>\n",
       "      <td>71432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>06316bec7a49286f1f98d5acce24f923</td>\n",
       "      <td>47720</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-05 16:34:37</td>\n",
       "      <td>35</td>\n",
       "      <td>1721</td>\n",
       "      <td>71440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>06316bec7a49286f1f98d5acce24f923</td>\n",
       "      <td>25104</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-06-05 16:34:26</td>\n",
       "      <td>35</td>\n",
       "      <td>1721</td>\n",
       "      <td>42032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id book_id  rating        date_updated  \\\n",
       "20  06316bec7a49286f1f98d5acce24f923  575753       4 2012-06-05 16:35:39   \n",
       "21  06316bec7a49286f1f98d5acce24f923   47694       4 2012-06-05 16:35:15   \n",
       "22  06316bec7a49286f1f98d5acce24f923   47700       3 2012-06-05 16:34:57   \n",
       "23  06316bec7a49286f1f98d5acce24f923   47720       4 2012-06-05 16:34:37   \n",
       "24  06316bec7a49286f1f98d5acce24f923   25104       5 2012-06-05 16:34:26   \n",
       "\n",
       "    user_sup  user_id_seq  book_id_seq  \n",
       "20        35         1721        73285  \n",
       "21        35         1721        71428  \n",
       "22        35         1721        71432  \n",
       "23        35         1721        71440  \n",
       "24        35         1721        42032  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print number of users and items\n",
    "print(f\"number of unique users: {_df_interactions['user_id'].nunique()}\")\n",
    "print(f\"number of unique items: {_df_interactions['book_id'].nunique()}\")\n",
    "processed_df_interactions = preprocess(_df_interactions.copy())\n",
    "# display(processed_df_interactions.head(5))\n",
    "print(f\"number of unique users: {processed_df_interactions['user_id'].nunique()}\")\n",
    "print(f\"number of unique items: {processed_df_interactions['book_id'].nunique()}\")\n",
    "# create sequential ids\n",
    "processed_df_interactions['user_id_seq'] = processed_df_interactions['user_id'].astype('category').cat.codes\n",
    "processed_df_interactions['book_id_seq'] = processed_df_interactions['book_id'].astype('category').cat.codes\n",
    "# merge book id and rating for easier \n",
    "display(processed_df_interactions.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the mapping from user/book id's to their sequential id in an external file. This might come in handy in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df_interactions[['user_id', 'user_id_seq']].drop_duplicates().to_pickle(\"./data/user_id_map.pkl\")\n",
    "processed_df_interactions[['book_id', 'book_id_seq']].drop_duplicates().to_pickle(\"./data/book_id_map.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort the interactions by their date and group them by user. This allows us to perform a session-based train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort on date and group per user\n",
    "sessions_df = processed_df_interactions.sort_values(['date_updated'],ascending=True).groupby(by='user_id_seq', as_index=False)[['book_id_seq','date_updated', 'rating']].agg(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform session-based split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eb3bc164f1405ca146aa55d581308b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733c53227744455691de5408db0561f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_seq</th>\n",
       "      <th>book_id_seq</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>rating</th>\n",
       "      <th>history</th>\n",
       "      <th>future</th>\n",
       "      <th>history_ratings</th>\n",
       "      <th>future_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[49283, 53514, 53515, 53516, 53522, 53519, 535...</td>\n",
       "      <td>[2013-06-21 17:23:44, 2013-06-21 17:24:05, 201...</td>\n",
       "      <td>[4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>[49283, 53514, 53515, 53516, 53522, 53519, 535...</td>\n",
       "      <td>[53512, 53508, 53520, 53509, 53513, 72017, 720...</td>\n",
       "      <td>[4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 4, 4, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[70584, 81684, 14070, 10809, 69705, 29863, 341...</td>\n",
       "      <td>[2012-10-21 16:23:19, 2012-10-21 16:27:04, 201...</td>\n",
       "      <td>[5, 5, 4, 4, 5, 4, 4, 5, 4, 4, 4, 4, 5]</td>\n",
       "      <td>[70584, 81684, 14070, 10809, 69705, 29863, 341...</td>\n",
       "      <td>[10030, 13982, 8144, 19061]</td>\n",
       "      <td>[5, 5, 4, 4, 5, 4, 4, 5, 4]</td>\n",
       "      <td>[4, 4, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[86771, 86776, 86912, 86890, 1087, 69, 85992, ...</td>\n",
       "      <td>[2008-02-22 22:33:45, 2008-02-23 03:14:49, 200...</td>\n",
       "      <td>[5, 4, 3, 4, 3, 5, 3, 4, 4, 5, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>[86771, 86776, 86912, 86890, 1087, 69, 85992, ...</td>\n",
       "      <td>[83894, 72445, 16120, 58134, 3327, 86827, 63486]</td>\n",
       "      <td>[5, 4, 3, 4, 3, 5, 3, 4, 4, 5, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 3, 4, 4, 4, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[71311, 73341, 56070, 70016, 82251, 86852, 859...</td>\n",
       "      <td>[2013-11-10 22:46:12, 2013-11-10 22:47:06, 201...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 4, 5, 5, 3, 5, ...</td>\n",
       "      <td>[71311, 73341, 56070, 70016, 82251, 86852, 859...</td>\n",
       "      <td>[73097, 27581, 11308, 74054, 22902, 65494, 785...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 4, 5, 5, 3, 5, ...</td>\n",
       "      <td>[5, 5, 4, 5, 5, 5, 5, 5, 5, 3, 2, 5, 5, 5, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[71311, 73815, 17559, 59228, 70489, 81010, 879...</td>\n",
       "      <td>[2012-10-19 15:54:06, 2012-10-19 16:03:30, 201...</td>\n",
       "      <td>[5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[71311, 73815, 17559, 59228, 70489, 81010, 879...</td>\n",
       "      <td>[71654, 71656, 87721, 71653]</td>\n",
       "      <td>[5, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[4, 4, 4, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id_seq                                        book_id_seq  \\\n",
       "0            0  [49283, 53514, 53515, 53516, 53522, 53519, 535...   \n",
       "1            1  [70584, 81684, 14070, 10809, 69705, 29863, 341...   \n",
       "2            2  [86771, 86776, 86912, 86890, 1087, 69, 85992, ...   \n",
       "3            3  [71311, 73341, 56070, 70016, 82251, 86852, 859...   \n",
       "4            4  [71311, 73815, 17559, 59228, 70489, 81010, 879...   \n",
       "\n",
       "                                        date_updated  \\\n",
       "0  [2013-06-21 17:23:44, 2013-06-21 17:24:05, 201...   \n",
       "1  [2012-10-21 16:23:19, 2012-10-21 16:27:04, 201...   \n",
       "2  [2008-02-22 22:33:45, 2008-02-23 03:14:49, 200...   \n",
       "3  [2013-11-10 22:46:12, 2013-11-10 22:47:06, 201...   \n",
       "4  [2012-10-19 15:54:06, 2012-10-19 16:03:30, 201...   \n",
       "\n",
       "                                              rating  \\\n",
       "0  [4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, ...   \n",
       "1            [5, 5, 4, 4, 5, 4, 4, 5, 4, 4, 4, 4, 5]   \n",
       "2  [5, 4, 3, 4, 3, 5, 3, 4, 4, 5, 4, 4, 4, 4, 4, ...   \n",
       "3  [5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 4, 5, 5, 3, 5, ...   \n",
       "4               [5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]   \n",
       "\n",
       "                                             history  \\\n",
       "0  [49283, 53514, 53515, 53516, 53522, 53519, 535...   \n",
       "1  [70584, 81684, 14070, 10809, 69705, 29863, 341...   \n",
       "2  [86771, 86776, 86912, 86890, 1087, 69, 85992, ...   \n",
       "3  [71311, 73341, 56070, 70016, 82251, 86852, 859...   \n",
       "4  [71311, 73815, 17559, 59228, 70489, 81010, 879...   \n",
       "\n",
       "                                              future  \\\n",
       "0  [53512, 53508, 53520, 53509, 53513, 72017, 720...   \n",
       "1                        [10030, 13982, 8144, 19061]   \n",
       "2   [83894, 72445, 16120, 58134, 3327, 86827, 63486]   \n",
       "3  [73097, 27581, 11308, 74054, 22902, 65494, 785...   \n",
       "4                       [71654, 71656, 87721, 71653]   \n",
       "\n",
       "                                     history_ratings  \\\n",
       "0   [4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4]   \n",
       "1                        [5, 5, 4, 4, 5, 4, 4, 5, 4]   \n",
       "2         [5, 4, 3, 4, 3, 5, 3, 4, 4, 5, 4, 4, 4, 4]   \n",
       "3  [5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 4, 5, 5, 3, 5, ...   \n",
       "4                           [5, 4, 4, 4, 4, 4, 4, 4]   \n",
       "\n",
       "                                      future_ratings  \n",
       "0                           [4, 4, 4, 4, 4, 5, 5, 5]  \n",
       "1                                       [4, 4, 4, 5]  \n",
       "2                              [4, 3, 4, 4, 4, 3, 4]  \n",
       "3  [5, 5, 4, 5, 5, 5, 5, 5, 5, 3, 2, 5, 5, 5, 4, ...  \n",
       "4                                       [4, 4, 4, 4]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to perform split\n",
    "def split(row, col, percentage_train):\n",
    "    items = row[col]\n",
    "    no_train_items = math.floor(len(items) * percentage_train)\n",
    "    return items[0:no_train_items], items[no_train_items:]\n",
    "\n",
    "# Split dataset into 0.7 training and 0.3 test samples, split in the temporal dimension.\n",
    "percentage_train = 0.7\n",
    "# train_items, test_items = split(items, percentage_train)\n",
    "sessions_df[['history', 'future']] = sessions_df.progress_apply(lambda row: split(row, 'book_id_seq', percentage_train), axis=1, result_type='expand')\n",
    "sessions_df[['history_ratings', 'future_ratings']] = sessions_df.progress_apply(lambda row: split(row, 'rating', percentage_train), axis=1, result_type='expand')\n",
    "display(sessions_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a sparse representation of the user-item interaction matrix for our train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f1740d465f4da09f7bd7057c005135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13fbd358bc14c54822efe4a734d5f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_sparse_repr(df, column, shape):\n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        items = row[column]\n",
    "        item_ids.extend(items)\n",
    "        user = row['user_id_seq']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        ratings = row[column + \"_ratings\"]\n",
    "        values.extend(ratings)\n",
    "    matrix = scipy.sparse.coo_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n",
    "    \n",
    "\n",
    "shape = (processed_df_interactions['user_id_seq'].max() + 1,  processed_df_interactions['book_id_seq'].max() + 1)\n",
    "train = create_sparse_repr(sessions_df, column='history', shape=shape)\n",
    "test = create_sparse_repr(sessions_df, column='future', shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the train and test set externally to be used in the training and evaluating notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('./data/train.npz', train)\n",
    "scipy.sparse.save_npz('./data/test.npz', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
